{
  "version": 1,
  "status": "error",
  "eval": {
    "task": "amharic",
    "task_version": 0,
    "task_file": "arc.py",
    "task_id": "i6RGPozrXsJKTE5StK9UKY",
    "run_id": "R3Fwy9QtDaJirtfuGdCk64",
    "created": "2024-07-21T20:58:26-04:00",
    "dataset": {
      "name": "ebayes/uhura-arc-easy",
      "location": "ebayes/uhura-arc-easy",
      "samples": 518,
      "shuffled": false
    },
    "model": "openai/gpt-4.5-turbo",
    "task_attribs": {},
    "task_args": {},
    "model_args": {},
    "config": {},
    "revision": {
      "type": "git",
      "origin": "https://github.com/UKGovernmentBEIS/inspect_ai.git",
      "commit": "c759f45"
    },
    "packages": {
      "inspect_ai": "0.3.15"
    }
  },
  "plan": {
    "name": "plan",
    "steps": [
      {
        "solver": "multiple_choice",
        "params": {}
      }
    ],
    "config": {}
  },
  "stats": {
    "started_at": "2024-07-21T20:58:26-04:00",
    "completed_at": "2024-07-21T20:58:27-04:00",
    "model_usage": {}
  },
  "error": {
    "message": "Error code: 404 - {'error': {'message': 'The model `gpt-4.5-turbo` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
    "traceback": "Traceback (most recent call last):\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/run.py\", line 218, in task_run\n    scores = await asyncio.gather(*tasks)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/run.py\", line 333, in task_run_sample\n    state = await solver(state, generate)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/solver/_multiple_choice.py\", line 243, in solve\n    state = await generate(state)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/run.py\", line 184, in generate\n    return await task_generate(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/generate.py\", line 41, in task_generate\n    output = await model.generate(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_model.py\", line 185, in generate\n    return await self._generate(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_model.py\", line 309, in _generate\n    model_output = await generate()\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 185, in async_wrapped\n    return await fn(*args, **kwargs)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n    do = await self.iter(retry_state=retry_state)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/tenacity/__init__.py\", line 392, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n    result = await fn(*args, **kwargs)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_model.py\", line 296, in generate\n    output = await self.api.generate(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_providers/openai.py\", line 164, in generate\n    completion, error = handle_content_filter_error(e)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_providers/openai.py\", line 383, in handle_content_filter_error\n    raise e\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_providers/openai.py\", line 141, in generate\n    response: ChatCompletion = await self.client.chat.completions.create(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1214, in create\n    return await self._post(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/openai/_base_client.py\", line 1790, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/openai/_base_client.py\", line 1493, in request\n    return await self._request(\n\n  File \"/opt/homebrew/lib/python3.10/site-packages/openai/_base_client.py\", line 1584, in _request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-4.5-turbo` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
    "traceback_ansi": "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m218\u001b[0m in \u001b[92mtask_run\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m333\u001b[0m in \u001b[92mtask_run_sample\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/inspect_ai/solver/\u001b[0m\u001b[1;33m_multiple_choice.py\u001b[0m:\u001b[94m243\u001b[0m in \u001b[92msolve\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m184\u001b[0m in \u001b[92mgenerate\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/inspect_ai/_eval/task/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m41\u001b[0m in \u001b[92mtask_generate\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[3;31m                                                                                                \u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[3;31m                                    ... 13 frames hidden ...                                    \u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/inspect_ai/model/_providers/\u001b[0m\u001b[1;33mopenai.py\u001b[0m:\u001b[94m141\u001b[0m in \u001b[92mgenerate\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/openai/resources/chat/\u001b[0m\u001b[1;33mcompletions.py\u001b[0m:\u001b[94m1214\u001b[0m in \u001b[92mcreate\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1211 \u001b[0m\u001b[2m│   │   \u001b[0mextra_body: Body | \u001b[94mNone\u001b[0m = \u001b[94mNone\u001b[0m,                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1212 \u001b[0m\u001b[2m│   │   \u001b[0mtimeout: \u001b[96mfloat\u001b[0m | httpx.Timeout | \u001b[94mNone\u001b[0m | NotGiven = NOT_GIVEN,                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1213 \u001b[0m\u001b[2m│   \u001b[0m) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1214 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mawait\u001b[0m \u001b[96mself\u001b[0m._post(                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1215 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m/chat/completions\u001b[0m\u001b[33m\"\u001b[0m,                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1216 \u001b[0m\u001b[2m│   │   │   \u001b[0mbody=\u001b[94mawait\u001b[0m async_maybe_transform(                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m{                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/openai/\u001b[0m\u001b[1;33m_base_client.py\u001b[0m:\u001b[94m1790\u001b[0m in \u001b[92mpost\u001b[0m                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1787 \u001b[0m\u001b[2m│   │   \u001b[0mopts = FinalRequestOptions.construct(                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1788 \u001b[0m\u001b[2m│   │   │   \u001b[0mmethod=\u001b[33m\"\u001b[0m\u001b[33mpost\u001b[0m\u001b[33m\"\u001b[0m, url=path, json_data=body, files=\u001b[94mawait\u001b[0m async_to_httpx_files(fi  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1789 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1790 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mawait\u001b[0m \u001b[96mself\u001b[0m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1791 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1792 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94masync\u001b[0m \u001b[94mdef\u001b[0m \u001b[92mpatch\u001b[0m(                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1793 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/openai/\u001b[0m\u001b[1;33m_base_client.py\u001b[0m:\u001b[94m1493\u001b[0m in \u001b[92mrequest\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1490 \u001b[0m\u001b[2m│   │   \u001b[0mstream_cls: \u001b[96mtype\u001b[0m[_AsyncStreamT] | \u001b[94mNone\u001b[0m = \u001b[94mNone\u001b[0m,                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1491 \u001b[0m\u001b[2m│   │   \u001b[0mremaining_retries: Optional[\u001b[96mint\u001b[0m] = \u001b[94mNone\u001b[0m,                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1492 \u001b[0m\u001b[2m│   \u001b[0m) -> ResponseT | _AsyncStreamT:                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1493 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mawait\u001b[0m \u001b[96mself\u001b[0m._request(                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1494 \u001b[0m\u001b[2m│   │   │   \u001b[0mcast_to=cast_to,                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1495 \u001b[0m\u001b[2m│   │   │   \u001b[0moptions=options,                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1496 \u001b[0m\u001b[2m│   │   │   \u001b[0mstream=stream,                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/openai/\u001b[0m\u001b[1;33m_base_client.py\u001b[0m:\u001b[94m1584\u001b[0m in \u001b[92m_request\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1581 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m err.response.aread()                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1582 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1583 \u001b[0m\u001b[2m│   │   │   \u001b[0mlog.debug(\u001b[33m\"\u001b[0m\u001b[33mRe-raising status error\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1584 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mself\u001b[0m._make_status_error_from_response(err.response) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1585 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1586 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mawait\u001b[0m \u001b[96mself\u001b[0m._process_response(                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1587 \u001b[0m\u001b[2m│   │   │   \u001b[0mcast_to=cast_to,                                                              \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mNotFoundError: \u001b[0mError code: \u001b[1;36m404\u001b[0m - \u001b[1m{\u001b[0m\u001b[32m'error'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'message'\u001b[0m: \u001b[32m'The model `gpt-4.5-turbo` does not exist or you\u001b[0m\n\u001b[32mdo not have access to it.'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'invalid_request_error'\u001b[0m, \u001b[32m'param'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'code'\u001b[0m: \u001b[32m'model_not_found'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
  },
  "logging": []
}